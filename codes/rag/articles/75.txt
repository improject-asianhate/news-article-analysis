How Anti-Asian Activity Online Set the Stage for Real-World Violence

Davey Alba

New York Times

2021-03-19

Protesters gather for a silent vigil in the Chinatown neighborhood of Washington on Wednesday, March 17, 2021, after eight people were shot to death at three spas in the Atlanta area on Tuesday evening. On platforms such as Telegram and 4chan, racist memes and posts about Asian-Americans have created fear and dehumanization. (Shuran Huang/The New York Times)

In January, a new group popped up on the messaging app Telegram, named after an Asian slur.

Hundreds of people quickly joined. Many members soon began posting caricatures of Asians with exaggerated facial features, memes of Asian people eating dog meat and images of U.S. soldiers inflicting violence during the Vietnam War.

This week, after a gunman killed eight people — including six women of Asian descent — at massage parlors in and near Atlanta, the Telegram channel linked to a poll that asked, “Appalled by the recent attacks on Asians?” The top answer, with 84% of the vote, was that the violence was “justified retaliation for COVID.”

The Telegram group was a sign of how anti-Asian sentiment has flared up in corners of the internet, amplifying racist and xenophobic tropes just as attacks against Asian Americans have surged. On messaging apps like Telegram and on internet forums like 4chan, anti-Asian groups and discussion threads have been increasingly active since November, especially on far-right message boards such as The Donald, researchers said.

The activity follows a rise in anti-Asian misinformation last spring after the coronavirus, which first emerged in China, began spreading around the world. On Facebook and Twitter, people blamed the pandemic on China, with users posting hashtags such as #gobacktochina and #makethecommiechinesepay. Those hashtags spiked when former President Donald Trump last year called COVID-19 the “Chinese virus” and “Kung Flu.”

While some of the online activity tailed off before the November election, its reemergence has helped lay the groundwork for real-world actions, researchers said. The fatal shootings in Atlanta this week, which have led to an outcry over treatment of Asian Americans even as the suspect said he was trying to cure a “sexual addiction,” were preceded by a swell of racially motivated attacks against Asian Americans in places like New York and the San Francisco Bay Area, according to the advocacy group Stop AAPI Hate.

“Surges in anti-Asian rhetoric online means increased risk of real-world events targeting that group of people,” said Alex Goldenberg, an analyst at the Network Contagion Research Institute at Rutgers University, which tracks misinformation and extremism online. 

He added that the anti-China coronavirus misinformation — including the false narrative that the Chinese government purposely created COVID-19 as a bioweapon — had created an atmosphere of fear and invective.

Anti-Asian speech online has typically not been as overt as anti-Semitic or anti-Black groups, memes and posts, researchers said. On Facebook and Twitter, posts expressing anti-Asian sentiments have often been woven into conspiracy theory groups such as QAnon and in white nationalist and pro-Trump enclaves. Goldenberg said forms of hatred against Black people and Jews have deep roots in extremism in the United States and that the anti-Asian memes and tropes have been more “opportunistically weaponized.”

But that does not make the anti-Asian hate speech online less insidious. Melissa Ryan, CEO of Card Strategies, a consulting firm that researches disinformation, said the misinformation and racist speech has led to a “dehumanization” of certain groups of people and to an increased risk of violence.

Negative Asian American tropes have long existed online but began increasing last March as parts of the United States went into lockdown over the coronavirus. That month, politicians including Rep. Paul Gosar, R-Ariz., and Rep. Kevin McCarthy, R-Calif., used the terms “Wuhan virus” and “Chinese coronavirus” to refer to COVID-19 in their tweets.

Those terms then began trending online, according to a study from the University of California, Berkeley. On the day Gosar posted his tweet, usage of the term “Chinese virus” jumped 650% on Twitter; a day later there was an 800% increase in their usage in conservative news articles, the study found.

Trump also posted eight times on Twitter last March about the “Chinese virus,” causing vitriolic reactions. In the replies section of one of his posts, a Trump supporter responded, “U caused the virus,” directing the comment to an Asian Twitter user who had cited U.S. death statistics for COVID-19. The Trump fan added a slur about Asian people. 

In a study this week from the University of California, San Francisco, researchers who examined 700,000 tweets before and after Trump’s March 2020 posts found that people who posted the hashtag #chinesevirus were more likely to use racist hashtags, including #bateatingchinese.

“There’s been a lot of discussion that ‘Chinese virus’ isn’t racist and that it can be used,” said Yulin Hswen, an assistant professor of epidemiology at the University of California, San Francisco, who conducted the research. But the term, she said, has turned into “a rallying cry to be able to gather and galvanize people who have these feelings, as well as normalize racist beliefs.”

Representatives for Trump, McCarthy and Gosar did not respond to requests for comment.

Misinformation linking the coronavirus to anti-Asian beliefs also rose last year. Since last March, there have been nearly 8 million mentions of anti-Asian speech online, much of it falsehoods, according to Zignal Labs, a media insights firm.

In one example, a Fox News article from April that went viral baselessly said that the coronavirus was created in a lab in the Chinese city of Wuhan and intentionally released. The article was liked and shared more than 1 million times on Facebook and retweeted 78,800 times on Twitter, according to data from Zignal and CrowdTangle, a Facebook-owned tool for analyzing social media.

By the middle of last year, the misinformation had started subsiding as election-related commentary increased. The anti-Asian sentiment ended up migrating to platforms like 4chan and Telegram, researchers said.

But it still occasionally flared up, such as when Dr. Li-Meng Yan, a researcher from Hong Kong, made unproven assertions last fall that the coronavirus was a bioweapon engineered by China. In the United States, Yan became a right-wing media sensation. Her appearance on Tucker Carlson’s Fox News show in September has racked up at least 8.8 million views online. 

In November, anti-Asian speech surged anew. That was when conspiracies about a “new world order” related to President Joe Biden’s election victory began circulating, said researchers from the Network Contagion Research Institute. Some posts that went viral painted Biden as a puppet of the Chinese Communist Party.

In December, slurs about Asians and the term “Kung Flu” rose by 65% on websites and apps like Telegram, 4chan and The Donald, compared with the monthly average mentions from the previous 11 months on the same platforms, according to the Network Contagion Research Institute. The activity remained high in January and last month.

During this second surge, calls for violence against Asian Americans became commonplace.

“Filipinos are not Asians because Asians are smart,” read a post in a Telegram channel that depicted a dog holding a gun to its head.

After the shootings in Atlanta, a doctored screenshot of what looked like a Facebook post from the suspect circulated on Facebook and Twitter this week. The post featured a miasma of conspiracies about China engaging in a COVID-19 cover-up and wild theories about how it was planning to “secure global domination for the 21st century.”

Facebook and Twitter eventually ruled that the screenshot was fake and blocked it. But by then, the post had been shared and liked hundreds of times on Twitter and more than 4,000 times on Facebook. 