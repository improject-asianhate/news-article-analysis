{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top N concepts of articles written by asian and non-asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/1btgs6694qx9t060q62cqxkm0000gn/T/ipykernel_57760/636063986.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ms = pd.read_csv(\"MS_result.csv\")\n",
    "nms = pd.read_csv(\"NMS_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(data: pd.DataFrame, from_asian: bool, n: int=10) -> dict:\n",
    "    \"\"\"\n",
    "    Note\n",
    "        data should have columns named by \"Key\", \"Value from Asian\", and \"Value from NonAsian\"\n",
    "    Return\n",
    "        dictionary with keys are in \"Key\", values are amount of paper which related to topic\n",
    "    \"\"\"\n",
    "    col = \"Value from Asian\" if from_asian else \"Value from NonAsian\"\n",
    "    temp = (sorted_data:=data.sort_values(by=[col], ascending=False).head(n))[col]\n",
    "    denominater = sum(data[col])\n",
    "    keys = sorted_data[\"Key\"]\n",
    "    res = {topic.strip(): round(counter / denominater, 4) for topic, counter in zip(keys, temp)}\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr. coef. between intersection: [[1.         0.92735375]\n",
      " [0.92735375 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "asian = get_top_n(nms, True)\n",
    "non_asian = get_top_n(nms, False)\n",
    "\n",
    "\"\"\"Correlation coefficient for same topic in MS and NMS\"\"\"\n",
    "keys = set(asian.keys()).intersection(set(non_asian.keys()))\n",
    "x = [asian[key] for key in keys]\n",
    "y = [non_asian[key] for key in keys]\n",
    "print(f\"corr. coef. between intersection: {np.corrcoef(x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr. coef. between union: [[1.         0.83502049]\n",
      " [0.83502049 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/1btgs6694qx9t060q62cqxkm0000gn/T/ipykernel_57760/2815126215.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a[\"Value from Asian\"] = (a.loc[:, \"Value from Asian\"] / sum_asian).apply(lambda x: round(x, 4)).to_list()\n",
      "/var/folders/lt/1btgs6694qx9t060q62cqxkm0000gn/T/ipykernel_57760/2815126215.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a[\"Value from NonAsian\"] = (a.loc[:, \"Value from NonAsian\"] / sum_nonasian).apply(lambda x: round(x, 4)).to_list()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value from Asian</th>\n",
       "      <th>Value from NonAsian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Racism (general)</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Anti-Asian hate crimes</td>\n",
       "      <td>0.0861</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-19 or coronavirus or pandemic</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.0606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Worry about safety</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.0404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Verbal harassment</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>“China/Chinese virus” or “Kung flu/plague” or ...</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.0202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perpetual foreigner (or forever foreigner or g...</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Racism (gendered, misogynistic) or racism towa...</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Impacts of racism on AA population (unemployme...</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Stop AAPI Hate</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Color blind/minimizing racism</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Key  Value from Asian  \\\n",
       "73                                   Racism (general)            0.1049   \n",
       "70                             Anti-Asian hate crimes            0.0861   \n",
       "4                 COVID-19 or coronavirus or pandemic            0.0599   \n",
       "17                                 Worry about safety            0.0599   \n",
       "59                                  Verbal harassment            0.0562   \n",
       "64  “China/Chinese virus” or “Kung flu/plague” or ...            0.0524   \n",
       "10  Perpetual foreigner (or forever foreigner or g...            0.0449   \n",
       "55  Racism (gendered, misogynistic) or racism towa...            0.0375   \n",
       "2   Impacts of racism on AA population (unemployme...            0.0300   \n",
       "48                                     Stop AAPI Hate            0.0150   \n",
       "29                      Color blind/minimizing racism            0.0112   \n",
       "\n",
       "    Value from NonAsian  \n",
       "73               0.1263  \n",
       "70               0.0909  \n",
       "4                0.0606  \n",
       "17               0.0404  \n",
       "59               0.0581  \n",
       "64               0.0202  \n",
       "10               0.0177  \n",
       "55               0.0480  \n",
       "2                0.0227  \n",
       "48               0.0303  \n",
       "29               0.0303  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Correlation coefficient for same topic in MS and NMS\"\"\"\n",
    "keys = list(set(asian.keys()).union(set(non_asian.keys())))\n",
    "sum_asian = sum(nms[\"Value from Asian\"])\n",
    "sum_nonasian = sum(nms[\"Value from NonAsian\"])\n",
    "x = nms[nms[\"Key\"].isin(keys)][\"Value from Asian\"].to_numpy() / sum_asian\n",
    "y = nms[nms[\"Key\"].isin(keys)][\"Value from NonAsian\"].to_numpy() / sum_nonasian\n",
    "print(f\"corr. coef. between union: {np.corrcoef(x, y)}\")\n",
    "a = nms[nms[\"Key\"].isin(keys)]\n",
    "a[\"Value from Asian\"] = (a.loc[:, \"Value from Asian\"] / sum_asian).apply(lambda x: round(x, 4)).to_list()\n",
    "a[\"Value from NonAsian\"] = (a.loc[:, \"Value from NonAsian\"] / sum_nonasian).apply(lambda x: round(x, 4)).to_list()\n",
    "a = a.sort_values(by=[\"Value from Asian\", \"Value from NonAsian\"], ascending=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr. coef. between xor: [[ 1.         -0.93788893]\n",
      " [-0.93788893  1.        ]]\n",
      "0.016135325264822482\n",
      "0.005199813202518688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/1btgs6694qx9t060q62cqxkm0000gn/T/ipykernel_57760/2414046682.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a[\"Value from Asian\"] = (a.loc[:, \"Value from Asian\"] / sum_asian).apply(lambda x: round(x, 4)).to_list()\n",
      "/var/folders/lt/1btgs6694qx9t060q62cqxkm0000gn/T/ipykernel_57760/2414046682.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a[\"Value from NonAsian\"] = (a.loc[:, \"Value from NonAsian\"] / sum_nonasian).apply(lambda x: round(x, 4)).to_list()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value from Asian</th>\n",
       "      <th>Value from NonAsian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>“China/Chinese virus” or “Kung flu/plague” or ...</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.0202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perpetual foreigner (or forever foreigner or g...</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Impacts of racism on AA population (unemployme...</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Stop AAPI Hate</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Color blind/minimizing racism</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Key  Value from Asian  \\\n",
       "64  “China/Chinese virus” or “Kung flu/plague” or ...            0.0524   \n",
       "10  Perpetual foreigner (or forever foreigner or g...            0.0449   \n",
       "2   Impacts of racism on AA population (unemployme...            0.0300   \n",
       "48                                     Stop AAPI Hate            0.0150   \n",
       "29                      Color blind/minimizing racism            0.0112   \n",
       "\n",
       "    Value from NonAsian  \n",
       "64               0.0202  \n",
       "10               0.0177  \n",
       "2                0.0227  \n",
       "48               0.0303  \n",
       "29               0.0303  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = set(asian.keys()).symmetric_difference(set(non_asian.keys()))\n",
    "sum_asian = sum(nms[\"Value from Asian\"])\n",
    "sum_nonasian = sum(nms[\"Value from NonAsian\"])\n",
    "x = nms[nms[\"Key\"].isin(keys)][\"Value from Asian\"].to_numpy() / sum_asian\n",
    "y = nms[nms[\"Key\"].isin(keys)][\"Value from NonAsian\"].to_numpy() / sum_nonasian\n",
    "print(f\"corr. coef. between xor: {np.corrcoef(x, y)}\")\n",
    "print(np.std(x))\n",
    "print(np.std(y))\n",
    "a = nms[nms[\"Key\"].isin(keys)]\n",
    "a[\"Value from Asian\"] = (a.loc[:, \"Value from Asian\"] / sum_asian).apply(lambda x: round(x, 4)).to_list()\n",
    "a[\"Value from NonAsian\"] = (a.loc[:, \"Value from NonAsian\"] / sum_nonasian).apply(lambda x: round(x, 4)).to_list()\n",
    "a = a.sort_values(by=[\"Value from Asian\", \"Value from NonAsian\"], ascending=False)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Key                                                                                                                                                                                                                                                                                                                             |   Asian |   Non Asian |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------:|------------:|\n",
      "| “China/Chinese virus” or “Kung flu/plague” or “Wuhan virus/plague” or “Diseased Chinese” or “Asian Virus” or “Ramen Noodle flu”                                                                                                                                                                                                 |  0.0524 |      0.0202 |\n",
      "| Perpetual foreigner (or forever foreigner or go back to China or You don’t belong to here)                                                                                                                                                                                                                                      |  0.0449 |      0.0177 |\n",
      "| Impacts of racism on AA population (unemployment, mental health problems, trauma, PTSD, Asian Target Anxiety Syndrome,  negative emotions (sadness), distrust, isolating self, Asian-based business had poor business or was worried about being attacked, child well-being, increasingly purchasing guns to defend themselves) |  0.03   |      0.0227 |\n",
      "| Stop AAPI Hate                                                                                                                                                                                                                                                                                                                  |  0.015  |      0.0303 |\n",
      "| Color blind/minimizing racism                                                                                                                                                                                                                                                                                                   |  0.0112 |      0.0303 |\n"
     ]
    }
   ],
   "source": [
    "a.set_index(\"Key\", inplace=True)\n",
    "a.columns = [\"Asian\", \"Non Asian\"]\n",
    "print(a.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Racism (general)': 0.1049,\n",
       "  'Anti-Asian violence/ assaults/attacks': 0.1049,\n",
       "  'Anti-Asian hate crimes': 0.0861,\n",
       "  'Worry about safety': 0.0599,\n",
       "  'COVID-19 or coronavirus or pandemic': 0.0599,\n",
       "  'Verbal harassment': 0.0562,\n",
       "  '“China/Chinese virus” or “Kung flu/plague” or “Wuhan virus/plague” or “Diseased Chinese” or “Asian Virus” or “Ramen Noodle flu”': 0.0524,\n",
       "  'Perpetual foreigner (or forever foreigner or go back to China or You don’t belong to here)': 0.0449,\n",
       "  'Racism (gendered, misogynistic) or racism toward Asian American women)': 0.0375,\n",
       "  'Impacts of racism on AA population (unemployment, mental health problems, trauma, PTSD, Asian Target Anxiety Syndrome,\\xa0 negative emotions (sadness), distrust, isolating self, Asian-based business had poor business or was worried about being attacked, child well-being, increasingly purchasing guns to defend themselves)': 0.03},\n",
       " {'Racism (general)': 0.1263,\n",
       "  'Anti-Asian violence/ assaults/attacks': 0.1035,\n",
       "  'Anti-Asian hate crimes': 0.0909,\n",
       "  'COVID-19 or coronavirus or pandemic': 0.0606,\n",
       "  'Verbal harassment': 0.0581,\n",
       "  'Racism (gendered, misogynistic) or racism toward Asian American women)': 0.048,\n",
       "  'Discrimination': 0.0455,\n",
       "  'Worry about safety': 0.0404,\n",
       "  'Stop AAPI Hate': 0.0303,\n",
       "  'Color blind/minimizing racism': 0.0303})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asian, non_asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                                                                        |   NonAsian |\n",
      "|:-----------------------------------------------------------------------|-----------:|\n",
      "| Racism (general)                                                       |     0.1263 |\n",
      "| Anti-Asian violence/ assaults/attacks                                  |     0.1035 |\n",
      "| Anti-Asian hate crimes                                                 |     0.0909 |\n",
      "| COVID-19 or coronavirus or pandemic                                    |     0.0606 |\n",
      "| Verbal harassment                                                      |     0.0581 |\n",
      "| Racism (gendered, misogynistic) or racism toward Asian American women) |     0.048  |\n",
      "| Discrimination                                                         |     0.0455 |\n",
      "| Worry about safety                                                     |     0.0404 |\n",
      "| Stop AAPI Hate                                                         |     0.0303 |\n",
      "| Color blind/minimizing racism                                          |     0.0303 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([non_asian]).T\n",
    "df.columns = [\"NonAsian\"]\n",
    "print(df.to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
